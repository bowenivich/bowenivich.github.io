<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Basic Page Needs
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <meta charset="utf-8">

  
  <title>Digit Recognizer using PyTorch and KFold</title>
  
  <link rel="canonical" href="https://bowenfeng.com/2024/08/16/digit-recognizer/">
  
  <meta name="description" content="IntroductionConvolutional Neural Networks (CNNs) have become the standard for tasks involving image recognition because of their ability to automatica">
  
  
  <meta name="keywords" content="Bowen Feng">
  
  <meta name="author" content="Bowen Feng">
  
  
  
  <meta property="og:site_name" content="Bowen Feng" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Digit Recognizer using PyTorch and KFold" />
  
  <meta property="og:description" content="IntroductionConvolutional Neural Networks (CNNs) have become the standard for tasks involving image recognition because of their ability to automatica">
  
  <meta property="og:url" content="https://bowenfeng.com/2024/08/16/digit-recognizer/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Digit Recognizer using PyTorch and KFold">
  
  <meta name="twitter:description" content="IntroductionConvolutional Neural Networks (CNNs) have become the standard for tasks involving image recognition because of their ability to automatica">
  
  
  
  
  <meta name="twitter:url" content="https://bowenfeng.com/2024/08/16/digit-recognizer/" />

  <!-- Mobile Specific Metas
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <link rel="preload" href="/fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <link rel="icon" type="image/png" href="/images/favicon.png">

  <!-- Custom Theme Color Style
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  <style>
  a:not(.icon) {
    text-decoration-color: #BBA591;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #BBA591 50%
    );
  }
  blockquote {
    border-left: 8px solid #BBA591;
  }
  .nanobar .bar {
    background: #BBA591;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #BBA591;
    border-color: #BBA591;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #BBA591;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  ‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì -->
  

  
  <script src="/js/pic.min.js" defer></script>
  

  

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">üåÉ</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>üåá</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Hi there üëã
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a href="/Resume" class="ml">Resume</a>
          
        
          
          <a href="/Projects" class="ml">Projects</a>
          
        
        
          
            <a href="mailto:bowen.feng@queensu.ca" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h1>Digit Recognizer using PyTorch and KFold</h1>

  <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Convolutional Neural Networks (CNNs) have become the standard for tasks involving image recognition because of their ability to automatically detect important features in visual data. They are widely used in applications such as object detection, facial recognition, and self-driving cars. </p>
<p>Starting with the most fundamental task of digit recognition using the MNIST dataset which is considered as the ‚ÄúHello World‚Äù dataset of computer vision, this project aims to develop a strong understanding of CNNs in preparation for more complex image recognition tasks in the future. </p>
<p>Achieved the 84th on Kaggle! </p>
<h2 id="Rundown"><a href="#Rundown" class="headerlink" title="Rundown"></a>Rundown</h2><h3 id="Import-Datasets"><a href="#Import-Datasets" class="headerlink" title="Import Datasets"></a>Import Datasets</h3><p>The datasets are downloaded from the <a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/digit-recognizer/data">Digit Recognizer</a> competition on Kaggle. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(&#x27;digit-recognizer/train.csv&#x27;)</span><br><span class="line">test = pd.read_csv(&#x27;digit-recognizer/test.csv&#x27;)</span><br></pre></td></tr></table></figure>

<h3 id="Dataset-and-Data-Loader"><a href="#Dataset-and-Data-Loader" class="headerlink" title="Dataset and Data Loader"></a>Dataset and Data Loader</h3><blockquote>
<p>The <code>Dataset</code> and <code>DataLoader</code> classes encapsulate the process of pulling your data from storage and exposing it to your training loop in batches.</p>
<p>The <code>Dataset</code> is responsible for accessing and processing single instances of data.</p>
<p>The <code>DataLoader</code> pulls instances of data from the Dataset (either automatically or with a sampler that you define), collects them in batches, and returns them for consumption by your training loop. The DataLoader works with all kinds of datasets, regardless of the type of data they contain.</p>
</blockquote>
<p>Define 2 Dataset classes, transformations, and normalizations. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">class TrainDataset(Dataset):</span><br><span class="line">    def __init__(self, dataframe, transform=None):</span><br><span class="line">        self.labels = dataframe.iloc[:, 0].values</span><br><span class="line">        self.features = dataframe.iloc[:, 1:].values</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.labels)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        feature = self.features[index].reshape(28, 28).astype(np.uint8)</span><br><span class="line">        label = self.labels[index]</span><br><span class="line">        if self.transform:</span><br><span class="line">            feature = self.transform(feature)</span><br><span class="line">        return feature, label</span><br><span class="line"></span><br><span class="line">class TestDataset(Dataset):</span><br><span class="line">    def __init__(self, dataframe, transform=None):</span><br><span class="line">        self.features = dataframe.values</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.features)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        feature = self.features[index].reshape(28, 28).astype(np.uint8)</span><br><span class="line">        if self.transform:</span><br><span class="line">            feature = self.transform(feature)</span><br><span class="line">        return feature</span><br><span class="line"></span><br><span class="line">train_mean = train.drop(&#x27;label&#x27;, axis=1).values.mean()/255</span><br><span class="line">train_std = train.drop(&#x27;label&#x27;, axis=1).values.std()/255</span><br><span class="line"></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.RandomRotation(5),</span><br><span class="line">    transforms.RandomAffine(degrees=5, translate=(0.1, 0.1), scale=(0.9, 1.1)),</span><br><span class="line">    transforms.RandomPerspective(distortion_scale=0.1, p=0.25),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(train_mean, train_std)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">test_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(train_mean, train_std)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>The training set and testing set are ready. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_set = TrainDataset(train, transform=train_transform)</span><br><span class="line">testing_set = TestDataset(test, transform=test_transform)</span><br></pre></td></tr></table></figure>

<p>Note that the data transformation or augmentation as implemented here does <strong>not</strong> create new data permanently in the dataset. Instead, it applies the transformations <strong>on-the-fly</strong> during training. Each time a batch of data is requested from the <code>DataLoader</code>, the transformations are applied to that batch dynamically. They don‚Äôt take up additional memory or storage. </p>
<h3 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h3><p>Visualize the data as a sanity check. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(15, 6))</span><br><span class="line">for i in range(30):  </span><br><span class="line">    plt.subplot(3, 10, i+1)</span><br><span class="line">    plt.imshow(training_set.features[i].reshape((28, 28)), cmap=plt.cm.binary)</span><br><span class="line">    plt.title(training_set.labels[i])</span><br><span class="line">    plt.axis(&#x27;off&#x27;)</span><br><span class="line">plt.subplots_adjust(wspace=-0.1, hspace=-0.1)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p align="center">
  <img src="/images/digit-recognizer/visualization.png" />
</p>

<h3 id="The-Model"><a href="#The-Model" class="headerlink" title="The Model"></a>The Model</h3><p>Below is the neural network. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(1, 32, 3, padding=1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.BatchNorm2d(32),</span><br><span class="line">            nn.Conv2d(32, 32, 3, stride=2, padding=1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.BatchNorm2d(32),</span><br><span class="line">            nn.MaxPool2d(2, 2),</span><br><span class="line">            nn.Dropout(0.25)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(32, 64, 3, padding=1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.BatchNorm2d(64),</span><br><span class="line">            nn.Conv2d(64, 64, 3, stride=2, padding=1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.BatchNorm2d(64),</span><br><span class="line">            nn.MaxPool2d(2, 2),</span><br><span class="line">            nn.Dropout(0.25)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.conv3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(64, 128, 3, padding=1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.BatchNorm2d(128),</span><br><span class="line">            nn.MaxPool2d(2, 2),</span><br><span class="line">            nn.Dropout(0.25)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(128, 10),</span><br><span class="line">        )   </span><br><span class="line">        </span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = x.view(x.size(0), -1)</span><br><span class="line">        return self.fc(x)</span><br></pre></td></tr></table></figure>

<p>Below is a function to reset model weights for the <code>KFold</code>. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def reset_weights(m):</span><br><span class="line">    for layer in m.children():</span><br><span class="line">        if hasattr(layer, &#x27;reset_parameters&#x27;):</span><br><span class="line">            layer.reset_parameters()</span><br></pre></td></tr></table></figure>

<h3 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h3><p><code>KFold</code> from <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html">scikit-learn</a> is used to avoid overfitting. The training set is shuffled and split into 5 folds, 80% and 20% of which will be used to train and validate the model respectively. </p>
<p align="center">
  <img src="/images/digit-recognizer/structure.png" />
</p>

<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>Below are the parameters and variables for the training. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">n_splits = 5</span><br><span class="line">batch_size = 100</span><br><span class="line">learning_rate = 0.0001</span><br><span class="line">epochs = 100</span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">training_losses_list, validation_losses_list, validation_accuracies_list = [], [], []</span><br></pre></td></tr></table></figure>

<p>I‚Äôm using a Mac Studio, so I will use the <code>mps</code> device for GPU training acceleration. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(&#x27;mps&#x27;)</span><br></pre></td></tr></table></figure>

<p>Start training!</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">kf = KFold(n_splits=n_splits, shuffle=True)</span><br><span class="line"></span><br><span class="line">for fold, (training_ids, validation_ids) in enumerate(kf.split(training_set)):</span><br><span class="line">    training_sampler = SubsetRandomSampler(training_ids)</span><br><span class="line">    validation_sampler = SubsetRandomSampler(validation_ids)</span><br><span class="line">    training_loader = DataLoader(training_set, batch_size=batch_size, sampler=training_sampler)</span><br><span class="line">    validation_loader = DataLoader(training_set, batch_size=batch_size, sampler=validation_sampler)</span><br><span class="line">    </span><br><span class="line">    model = Net().to(device)</span><br><span class="line">    model.apply(reset_weights)</span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">    training_loss_min = np.inf</span><br><span class="line">    validation_loss_min = np.inf</span><br><span class="line">    training_losses, validation_losses, validation_accuracies = [], [], []</span><br><span class="line">    </span><br><span class="line">    for e in range(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        training_loss = 0</span><br><span class="line">        for features, labels in training_loader:</span><br><span class="line">            features, labels = features.to(device), labels.to(device)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = model(features)</span><br><span class="line">            loss = loss_fn(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            training_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        model.eval()</span><br><span class="line">        validation_loss = 0</span><br><span class="line">        correct, total = 0, 0</span><br><span class="line">        for features, labels in validation_loader:</span><br><span class="line">            features, labels = features.to(device), labels.to(device)</span><br><span class="line">            outputs = model(features)</span><br><span class="line">            loss = loss_fn(outputs, labels)</span><br><span class="line">            validation_loss += loss.item()</span><br><span class="line">            _, predicted = torch.max(outputs.data, 1)</span><br><span class="line">            total += labels.size(0)</span><br><span class="line">            correct += (predicted == labels).sum().item()</span><br><span class="line">        validation_accuracy = correct / total</span><br><span class="line"></span><br><span class="line">        training_losses.append(training_loss/total)</span><br><span class="line">        validation_losses.append(validation_loss/total)</span><br><span class="line">        validation_accuracies.append(validation_accuracy)</span><br><span class="line"></span><br><span class="line">        network_learned = (training_loss &lt; training_loss_min) &amp; (validation_loss &lt; validation_loss_min)</span><br><span class="line">        if network_learned:</span><br><span class="line">            training_loss_min = training_loss</span><br><span class="line">            validation_loss_min = validation_loss</span><br><span class="line">            torch.save(model.state_dict(), f&#x27;model_mnist_&#123;fold+1&#125;.pt&#x27;)</span><br><span class="line">            print(f&#x27;fold &#123;fold+1&#125; | epoch &#123;e+1&#125; | &#123;training_loss/total:.3f&#125; | &#123;validation_loss/total:.3f&#125; | &#123;validation_accuracy:.3f&#125; | network improved&#x27;)</span><br><span class="line">        else:</span><br><span class="line">            print(f&#x27;fold &#123;fold+1&#125; | epoch &#123;e+1&#125; | &#123;training_loss/total:.3f&#125; | &#123;validation_loss/total:.3f&#125; | &#123;validation_accuracy:.3f&#125;&#x27;)</span><br><span class="line">    </span><br><span class="line">    training_losses_list.append(training_losses)</span><br><span class="line">    validation_losses_list.append(validation_losses)</span><br><span class="line">    validation_accuracies_list.append(validation_accuracies)</span><br></pre></td></tr></table></figure>

<p>The best models are saved to local from the following folds and epochs. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fold 1 | epoch 100 | 0.001 | 0.000 | 0.992 | network improved</span><br><span class="line">fold 2 | epoch 94 | 0.001 | 0.000 | 0.993 | network improved</span><br><span class="line">fold 3 | epoch 86 | 0.001 | 0.000 | 0.994 | network improved</span><br><span class="line">fold 4 | epoch 88 | 0.001 | 0.000 | 0.993 | network improved</span><br><span class="line">fold 5 | epoch 97 | 0.001 | 0.000 | 0.992 | network improved</span><br></pre></td></tr></table></figure>

<p>Below is the visualization of the training losses and the validation losses. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">fig, [[ax1, ax2, ax3], [ax4, ax5, ax6]] = plt.subplots(nrows=2, ncols=3, figsize=(18, 4))</span><br><span class="line"></span><br><span class="line">ax1.plot(training_losses_list[0], label=&#x27;training_loss&#x27;)</span><br><span class="line">ax1.plot(validation_losses_list[0], label=&#x27;validation_loss&#x27;)</span><br><span class="line">ax1.set_title(&#x27;Fold 1&#x27;)</span><br><span class="line"></span><br><span class="line">ax2.plot(training_losses_list[1], label=&#x27;training_loss&#x27;)</span><br><span class="line">ax2.plot(validation_losses_list[1], label=&#x27;validation_loss&#x27;)</span><br><span class="line">ax2.set_title(&#x27;Fold 2&#x27;)</span><br><span class="line"></span><br><span class="line">ax3.plot(training_losses_list[2], label=&#x27;training_loss&#x27;)</span><br><span class="line">ax3.plot(validation_losses_list[1], label=&#x27;validation_loss&#x27;)</span><br><span class="line">ax3.set_title(&#x27;Fold 3&#x27;)</span><br><span class="line"></span><br><span class="line">ax4.plot(training_losses_list[3], label=&#x27;training_loss&#x27;)</span><br><span class="line">ax4.plot(validation_losses_list[3], label=&#x27;validation_loss&#x27;)</span><br><span class="line">ax4.set_title(&#x27;Fold 4&#x27;)</span><br><span class="line"></span><br><span class="line">ax5.plot(training_losses_list[4], label=&#x27;training_loss&#x27;)</span><br><span class="line">ax5.plot(validation_losses_list[4], label=&#x27;validation_loss&#x27;)</span><br><span class="line">ax5.set_title(&#x27;Fold 5&#x27;)</span><br><span class="line"></span><br><span class="line">training_losses_average = [sum(x)/len(x) for x in zip(*training_losses_list)]</span><br><span class="line">validation_losses_average = [sum(x)/len(x) for x in zip(*validation_losses_list)]</span><br><span class="line">ax6.plot(training_losses_average, label=&#x27;training_loss&#x27;)</span><br><span class="line">ax6.plot(validation_losses_average, label=&#x27;validation_loss&#x27;)</span><br><span class="line">ax6.set_title(&#x27;Average&#x27;)</span><br><span class="line"></span><br><span class="line">ax3.legend()</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>

<p align="center">
  <img src="/images/digit-recognizer/losses.png" />
</p>

<h3 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h3><p>I ensemble the 5 models saved from training to make the final predictions on the testing set. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">models = []</span><br><span class="line">for fold in range(0, 5):</span><br><span class="line">    model = Net().to(device)</span><br><span class="line">    model.load_state_dict(torch.load(f&#x27;model_mnist_&#123;fold+1&#125;.pt&#x27;, weights_only=False))</span><br><span class="line">    model.eval()</span><br><span class="line">    models.append(model)</span><br><span class="line"></span><br><span class="line">testing_loader = DataLoader(testing_set, batch_size=len(testing_set), shuffle=False)</span><br><span class="line"></span><br><span class="line">pred = np.zeros(280000).reshape(28000, 10)</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    for model in models:</span><br><span class="line">        for features in testing_loader:</span><br><span class="line">            features = features.to(device)</span><br><span class="line">            outputs = model(features)</span><br><span class="line">            pred += 0.2 * outputs.cpu().numpy()</span><br><span class="line"></span><br><span class="line">predictions = pd.DataFrame(np.argmax(pred, axis=1), columns=[&#x27;Label&#x27;])</span><br></pre></td></tr></table></figure>

<p>Save the predictions to local for submission. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">predictions.index += 1</span><br><span class="line">predictions.index.name = &#x27;ImageId&#x27;</span><br><span class="line">predictions.to_csv(&#x27;submission.csv&#x27;)</span><br></pre></td></tr></table></figure>

<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>The submission achieved an accuracy score of 0.99575, the 84th on the leaderboard at the time of submission. </p>
<p align="center">
  <img src="/images/digit-recognizer/leaderboard.png" />
</p>
  <p> ‚Äî Aug 16, 2024</p>
  


        </div>
        
        <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">&copy; 2024 Bowen Feng. 
      </p>
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/bowenivich" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://www.linkedin.com/in/bowen-feng/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="LinkedIn">
        <svg class="linkedin svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
      </a>
      

      

      
      <a class="ml-0 footer-link icon" href="https://www.instagram.com/bowenivich/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Instagram">
        <svg class="instagram svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Instagram</title><path d="M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z"/></svg>
      </a>
      

      

    </div>
  
</div>

      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>

  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>